{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc8d7cb",
   "metadata": {},
   "source": [
    "# Replication of Recommender Systems for Insurance Marketing\n",
    "\n",
    "Done by Luke Strassburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce68e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.pandas_utils import group_categoricals_tail\n",
    "import utils.pimpmatplotlib as pm\n",
    "from utils.xgbextras import stopping_at\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score,\n",
    "    fbeta_score\n",
    ")\n",
    "from xgboost.callback import EarlyStopping\n",
    "from lightgbm.callback import early_stopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9747f07",
   "metadata": {},
   "source": [
    "### Table 1: Insurance Product Possession: Period One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27cf1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAS_A_1    0.7810\n",
       "HAS_B_1    0.2193\n",
       "HAS_C_1    0.0110\n",
       "HAS_D_1    0.2068\n",
       "HAS_E_1    0.0193\n",
       "HAS_F_1    0.0223\n",
       "HAS_G_1    0.0243\n",
       "HAS_H_1    0.0073\n",
       "HAS_I_1    0.0204\n",
       "HAS_L_1    0.0321\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = os.path.join(\"..\", \"sample_data\")\n",
    "DATA_FILE = \"dataset.csv\"\n",
    "MODEL_TYPE = \"model\"\n",
    "CONFIG_FOLDER = os.path.join(\"config\")\n",
    "CONFIG_FILE = \"features.csv\"\n",
    "\n",
    "source_config = os.path.join(CONFIG_FOLDER, CONFIG_FILE)\n",
    "features = pd.read_csv(source_config, keep_default_na=False, na_values=[\"\"])\n",
    "index = features.loc[features[MODEL_TYPE] == \"index\", \"column\"].tolist()\n",
    "predictors = features.loc[features[MODEL_TYPE] == \"predictor\", \"column\"].tolist()\n",
    "labels = features.loc[features[MODEL_TYPE] == \"label\", \"column\"].tolist()\n",
    "categorical = features.loc[(features[\"categorical\"] == 1) & (features[\"column\"].isin(predictors)), \"column\"].tolist()\n",
    "\n",
    "index = features.loc[features[MODEL_TYPE] == \"index\", \"column\"].tolist()\n",
    "labels = features.loc[features[MODEL_TYPE] == \"label\", \"column\"].tolist()\n",
    "\n",
    "source_file = os.path.join(DATA_FOLDER, DATA_FILE)\n",
    "data = pd.read_csv(source_file, usecols=index+labels+[\"SET\"],\n",
    "        sep=\";\", decimal=\".\", encoding=\"latin1\",\n",
    "        keep_default_na = False, na_values = [\"\"])\n",
    "\n",
    "term1 = data[['HAS_A_1', 'HAS_B_1', 'HAS_C_1', 'HAS_D_1', 'HAS_E_1', 'HAS_F_1', 'HAS_G_1', 'HAS_H_1', 'HAS_I_1', 'HAS_L_1']]\n",
    "\n",
    "col_means = term1.mean()\n",
    "\n",
    "col_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca923186",
   "metadata": {},
   "source": [
    "### Table 2: Purchases Within Periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4de3f4",
   "metadata": {},
   "source": [
    "### Table 11: Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1af96",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16193ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CONFIG_FOLDER = os.path.join(\"config\")\n",
    "CONFIG_FILE = \"features.csv\"\n",
    "DATA_FOLDER = os.path.join(\"..\", \"sample_data\")\n",
    "DATA_FILE = \"dataset.csv\"\n",
    "MODELS_FOLDER = os.path.join(\"models\")\n",
    "RESULTS_FOLDER = os.path.join(\"results\")\n",
    "\n",
    "MODEL_TYPE = \"model\"\n",
    "TAG = \"lgb\"\n",
    "\n",
    "PREDICTIONS_FILE = \"_\".join([MODEL_TYPE, TAG, \"pred.csv\"])\n",
    "\n",
    "SAVE = True\n",
    "\n",
    "# lightgbm params\n",
    "# use an optimisation method to find the best params\n",
    "SEED = 17\n",
    "LGB_PARAMS = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 22,\n",
    "    \"min_data_in_leaf\": 500,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "    \"subsample\": 0.75,\n",
    "    \"learning_rate\": 0.1\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    pmp = pm.PimpPlot(save=SAVE, folder=os.path.join(RESULTS_FOLDER, \"plots\"))\n",
    "\n",
    "    # Load config\n",
    "    source_config = os.path.join(CONFIG_FOLDER, CONFIG_FILE)\n",
    "    features = pd.read_csv(source_config, keep_default_na=False, na_values=[\"\"])\n",
    "    #print(features.columns)\n",
    "    index = features.loc[features[MODEL_TYPE] == \"index\", \"column\"].tolist()\n",
    "    predictors = features.loc[features[MODEL_TYPE] == \"predictor\", \"column\"].tolist()\n",
    "    labels = features.loc[features[MODEL_TYPE] == \"label\", \"column\"].tolist()\n",
    "    categorical = features.loc[(features[\"categorical\"] == 1) & (features[\"column\"].isin(predictors)), \"column\"].tolist()\n",
    "\n",
    "    # Load data\n",
    "    source_file = os.path.join(DATA_FOLDER, DATA_FILE)\n",
    "    data = pd.read_csv(source_file, usecols=index+labels+predictors+[\"SET\"],\n",
    "                    sep=\";\", decimal=\".\", encoding=\"latin1\",\n",
    "                    keep_default_na = False, na_values = [\"\"])\n",
    "\n",
    "    # Preprocessing lightgbm\n",
    "    group_categoricals_tail(data, categorical)\n",
    "\n",
    "    # Label encoder categorical variables\n",
    "    label_encoding = {}\n",
    "    for col in categorical:\n",
    "        unique_values = data[col].unique().tolist()\n",
    "        label_encoding[col] = LabelEncoder()\n",
    "        label_encoding[col].fit(sorted(unique_values))\n",
    "        data[col] = label_encoding[col].transform(data[col].values)\n",
    "\n",
    "    # Split the dataset\n",
    "    indexes = {\"train\": None, \"valid\": None, \"test\": None}\n",
    "    for set_name in indexes.keys():\n",
    "        indexes[set_name] = np.where(data[\"SET\"] == set_name)[0]\n",
    "\n",
    "    # Get only relevant features\n",
    "    lgb_features = [x for x in sorted(data.columns.tolist()) if x not in labels + index + [\"SET\"]]\n",
    "\n",
    "    d = {}\n",
    "    for set_name, set_indexes in indexes.items():\n",
    "        if set_name == \"test\":\n",
    "            d[set_name] = data.loc[set_indexes, lgb_features].values\n",
    "        else:\n",
    "            d[set_name] = lgb.Dataset(data.loc[set_indexes, lgb_features], \n",
    "                                        feature_name=lgb_features, \n",
    "                                        categorical_feature=categorical, \n",
    "                                        free_raw_data=False)\n",
    "\n",
    "    predictions = {}\n",
    "    for label in labels:\n",
    "        print(\"----------------------------\", end=\"\\n\")\n",
    "        print(label, end=\"\\n\")\n",
    "        print(\"----------------------------\", end=\"\\n\\n\")\n",
    "        \n",
    "        print(\"Creating the Dataset...\")\n",
    "        for set_name, set_indexes in indexes.items():\n",
    "            if set_name == \"test\":\n",
    "                y_test = data.loc[set_indexes, label].values\n",
    "            else:\n",
    "                d[set_name].set_label(data.loc[set_indexes, label].values)\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        print(\"Training lightgbm...\")\n",
    "        bst = lgb.train(params=LGB_PARAMS, \n",
    "                        train_set=d[\"train\"],\n",
    "                        num_boost_round=3000, \n",
    "                        valid_sets=[d[\"valid\"]],\n",
    "                        callbacks=[early_stopping(stopping_rounds=5)])\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        print(\"Predictions and plots LGB...\")\n",
    "        pred_label = \"{0}_PRED_{1}\".format(label, TAG.upper())\n",
    "        predictions[pred_label] = bst.predict(d[\"test\"])\n",
    "        \n",
    "        print(\"Logloss: {}\".format(log_loss(y_test, predictions[pred_label])), end=\"\\n\\n\")\n",
    "\n",
    "        print(predictions[pred_label])\n",
    "\n",
    "        threshold_preds = (predictions[pred_label] > 0.5).astype(int)\n",
    "\n",
    "        auc_score = roc_auc_score(y_test, predictions[pred_label])\n",
    "        accuracy = accuracy_score(y_test, threshold_preds)\n",
    "        precision = precision_score(y_test, threshold_preds)\n",
    "        recall = recall_score(y_test, threshold_preds)\n",
    "        pr_auc = average_precision_score(y_test, predictions[pred_label])\n",
    "        f2_score = fbeta_score(y_test, threshold_preds, beta=2)\n",
    "        \n",
    "        print(f\"AUC {label}: {auc_score:.4f}\")\n",
    "        print(f\"Accuracy {label}: {accuracy:.4f}\")\n",
    "        print(f\"Precision {label}: {precision:.4f}\")\n",
    "        print(f\"Recall {label}: {recall:.4f}\")\n",
    "        print(f\"PR_AUC {label}: {pr_auc:.4f}\")\n",
    "        print(f\"F2-Score {label}: {f2_score:.4f}\")\n",
    "        \n",
    "        if TAG:\n",
    "            title = \"_\".join([TAG, label])\n",
    "        else:\n",
    "            title = label\n",
    "        pmp.plot_roc(y_test, predictions[pred_label], title)\n",
    "        pmp.plot_distributions(y_test, predictions[pred_label], title)\n",
    "        threshold = pmp.find_threshold_max_f1(y_test, predictions[pred_label], title, N = 100)\n",
    "        binary_predictions = np.where(predictions[pred_label] >= threshold, 1, 0)\n",
    "        pmp.plot_confusion_matrix(y_test, binary_predictions, [0, 1], title)\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        if SAVE:\n",
    "            print(\"Saving...\")\n",
    "            bst.save_model(os.path.join(MODELS_FOLDER, title + \".model\"))\n",
    "            print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.to_csv(os.path.join(RESULTS_FOLDER, PREDICTIONS_FILE), sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7ff99",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CONFIG_FOLDER = os.path.join(\"config\")\n",
    "CONFIG_FILE = \"features.csv\"\n",
    "DATA_FOLDER = os.path.join(\"..\", \"sample_data\")\n",
    "DATA_FILE = \"dataset.csv\"\n",
    "MODELS_FOLDER = os.path.join(\"models\")\n",
    "RESULTS_FOLDER = os.path.join(\"results\")\n",
    "\n",
    "MODEL_TYPE = \"model\"\n",
    "TAG = \"xgb\"\n",
    "\n",
    "PREDICTIONS_FILE = \"_\".join([MODEL_TYPE, TAG, \"pred.csv\"])\n",
    "\n",
    "SAVE = True\n",
    "\n",
    "# XGBoost params\n",
    "# use an optimisation method to find the best params\n",
    "SEED = 17\n",
    "XGB_PARAMS = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "    \"subsample\": 0.75,\n",
    "    \"gamma\": 5\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pmp = pm.PimpPlot(save=SAVE, folder=os.path.join(RESULTS_FOLDER, \"plots\"))\n",
    "\n",
    "    # Load config\n",
    "    source_config = os.path.join(CONFIG_FOLDER, CONFIG_FILE)\n",
    "    features = pd.read_csv(source_config, keep_default_na=False, na_values=[\"\"])\n",
    "    print(features.columns)\n",
    "    index = features.loc[features[MODEL_TYPE] == \"index\", \"column\"].tolist()\n",
    "    print(index)\n",
    "    predictors = features.loc[features[MODEL_TYPE] == \"predictor\", \"column\"].tolist()\n",
    "    labels = features.loc[features[MODEL_TYPE] == \"label\", \"column\"].tolist()\n",
    "    categorical = features.loc[(features[\"categorical\"] == 1) & (features[\"column\"].isin(predictors)), \"column\"].tolist()\n",
    "\n",
    "    # Load data\n",
    "    source_file = os.path.join(DATA_FOLDER, DATA_FILE)\n",
    "    data = pd.read_csv(source_file, usecols=index+labels+predictors+[\"SET\"],\n",
    "                    sep=\";\", decimal=\".\", encoding=\"latin1\",\n",
    "                    keep_default_na = False, na_values = [\"\"])\n",
    "\n",
    "    # Preprocessing XGBoost\n",
    "    group_categoricals_tail(data, categorical)\n",
    "    data = pd.get_dummies(data, columns=categorical).copy()\n",
    "\n",
    "    # Split the dataset\n",
    "    indexes = {\"train\": None, \"valid\": None, \"test\": None}\n",
    "    for set_name in indexes.keys():\n",
    "        indexes[set_name] = np.where(data[\"SET\"] == set_name)[0]\n",
    "\n",
    "    # Get only relevant features\n",
    "    xgb_features = [x for x in sorted(data.columns.tolist()) if x not in labels + index + [\"SET\"]]\n",
    "\n",
    "    d = {}\n",
    "    for set_name, set_indexes in indexes.items():\n",
    "        d[set_name] = xgb.DMatrix(data.loc[set_indexes, xgb_features])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    print(labels)\n",
    "    for label in labels:\n",
    "        print(\"----------------------------\", end=\"\\n\")\n",
    "        print(label, end=\"\\n\")\n",
    "        print(\"----------------------------\", end=\"\\n\\n\")\n",
    "        \n",
    "        print(\"Creating the DMatrix...\")\n",
    "        for set_name, set_indexes in indexes.items():\n",
    "            d[set_name].set_label(data.loc[set_indexes, label].values)\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        print(\"Training XGB...\")\n",
    "        bst = xgb.train(params=XGB_PARAMS, \n",
    "                        num_boost_round=3000, \n",
    "                        dtrain=d[\"train\"], evals=[(d[\"valid\"], \"val\")],\n",
    "                        callbacks=[EarlyStopping(rounds=10)])\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        print(\"Predictions and plots XGB...\")\n",
    "        pred_label = \"{0}_PRED_{1}\".format(label, TAG.upper())\n",
    "        predictions[pred_label] = bst.predict(d[\"test\"])\n",
    "        \n",
    "        print(\"Logloss: {}\".format(log_loss(d[\"test\"].get_label(), predictions[pred_label])), end=\"\\n\\n\")\n",
    "\n",
    "        threshold_preds = (predictions[pred_label] > 0.5).astype(int)\n",
    "        \n",
    "        auc_score = roc_auc_score(d[\"test\"].get_label(), predictions[pred_label])\n",
    "        accuracy = accuracy_score(d[\"test\"].get_label(), threshold_preds)\n",
    "        precision = precision_score(d[\"test\"].get_label(), threshold_preds)\n",
    "        recall = recall_score(d[\"test\"].get_label(), threshold_preds)\n",
    "        pr_auc = average_precision_score(d[\"test\"].get_label(), predictions[pred_label])\n",
    "        f2_score = fbeta_score(d[\"test\"].get_label(), threshold_preds, beta=2)\n",
    "        \n",
    "        print(f\"AUC {label}: {auc_score:.4f}\")\n",
    "        print(f\"Accuracy {label}: {accuracy:.4f}\")\n",
    "        print(f\"Precision {label}: {precision:.4f}\")\n",
    "        print(f\"Recall {label}: {recall:.4f}\")\n",
    "        print(f\"PR_AUC {label}: {pr_auc:.4f}\")\n",
    "        print(f\"F2-Score {label}: {f2_score:.4f}\")\n",
    "        \n",
    "        if TAG:\n",
    "            title = \"_\".join([TAG, label])\n",
    "        else:\n",
    "            title = label\n",
    "        pmp.plot_roc(d[\"test\"].get_label(), predictions[pred_label], title)\n",
    "        pmp.plot_distributions(d[\"test\"].get_label(), predictions[pred_label], title)\n",
    "        threshold = pmp.find_threshold_max_f1(d[\"test\"].get_label(), predictions[pred_label], title, N = 100)\n",
    "        binary_predictions = np.where(predictions[pred_label] >= threshold, 1, 0)\n",
    "        pmp.plot_confusion_matrix(d[\"test\"].get_label(), binary_predictions, [0, 1], title)\n",
    "        print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "        if SAVE:\n",
    "            print(\"Saving...\")\n",
    "            bst.save_model(os.path.join(MODELS_FOLDER, title + \".model\"))\n",
    "            print(\"Done!\", end=\"\\n\\n\")\n",
    "\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.to_csv(os.path.join(RESULTS_FOLDER, PREDICTIONS_FILE), sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
